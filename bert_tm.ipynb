{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New ones\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.utils import get_stop_words\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.models.nmf import Nmf\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from operator import itemgetter # Already part of base Python\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the full twitter corpus\n",
    "key_tweets = pd.read_csv('combined_key.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = key_tweets['text_cleaned_string'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the sentence transformer model and encode the text with it\n",
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "encoded_data = model.encode(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the k-means model and fit it to our text\n",
    "km = KMeans(n_clusters = 5, random_state = 42) # Using 5 clusters here\n",
    "km.fit(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to return topic per document \n",
    "def doc_topic_id(all_training, km, num_clusters):\n",
    "    clusters = km.labels_.tolist()\n",
    "    docs = {'document_text':all_training, 'topic_id':clusters}\n",
    "    frame = pd.DataFrame(docs, index = [clusters])\n",
    "    for cluster in range(0, num_clusters):\n",
    "        this_cluster_text = \\\n",
    "        frame[frame['topic_id'] == cluster]\n",
    "        all_text = \\\n",
    "        \" \".join(this_cluster_text['document_text'].astype(str))\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign to a dataframe and add original index values from the emails dataframe\n",
    "key_tweets['doc_id'] = key_tweets.index # Pull out index values into column\n",
    "\n",
    "topics_bert = doc_cluster_id(documents, km, 5) # Create dataframe\n",
    "topics_bert = topics_bert.set_index(key_tweets['doc_id']) # Assign doc_id from emails\n",
    "topics_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by topic and get most frequent 10 words per topic\n",
    "topics_bert_grouped = topics_bert.groupby(['cluster_id'])['document_text'].apply(','.join).reset_index()\n",
    "topics_bert_grouped['tokens'] = topics_bert_grouped['document_text'].apply(re_tokenizer.tokenize)\n",
    "\n",
    "topics_bert_words = []\n",
    "\n",
    "for i in topics_bert_grouped['tokens']:\n",
    "    counter = Counter(i)\n",
    "    topics_bert_words.append(counter.most_common(10))\n",
    "\n",
    "topics_bert_words = pd.DataFrame(topics_bert_words)\n",
    "topics_bert_words = topics_bert_words.transpose()\n",
    "topics_bert_words.columns = ['topic_1', 'topic_2', 'topic_3', 'topic_4', 'topic_5']\n",
    "topics_bert_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
